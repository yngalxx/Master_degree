{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as T\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from mean_average_precision import MetricBuilder\n",
    "\n",
    "sys.path.append('../src/')\n",
    "from newspapersdataset import (\n",
    "    NewspapersDataset, \n",
    "    prepare_data_for_dataloader\n",
    ")\n",
    "from functions import (\n",
    "    from_tsv_to_list,\n",
    "    collate_fn\n",
    ")\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "from image_size import get_image_size  # source: https://github.com/scardine/image_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('../saved_models/model.pth', map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'channel': 1, \n",
    "    'rescale': [1000, 1000],\n",
    "    'batch_size': 16,\n",
    "    'shuffle': False, \n",
    "    'num_workers': 2,\n",
    "    'main_dir': '/Users/alexdrozdz/Desktop/Studia/00. Seminarium magisterskie/Master_degree/',\n",
    "    'image_dir': '/Users/alexdrozdz/Desktop/Studia/00. Seminarium magisterskie/scraped_photos_final/',\n",
    "    'annotations_dir': '/Users/alexdrozdz/Desktop/Studia/00. Seminarium magisterskie/news-navigator/',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = T.Compose([\n",
    "    T.Grayscale(num_output_channels=parameters['channel']),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.5,), (0.5,)),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data \n",
    "expected = from_tsv_to_list(parameters['annotations_dir']+'dev-0/expected.tsv')\n",
    "in_file = from_tsv_to_list(parameters['annotations_dir']+'dev-0/in.tsv')\n",
    "img_paths = [parameters['image_dir']+path for path in in_file]\n",
    "\n",
    "data = prepare_data_for_dataloader(\n",
    "    img_dir=parameters['image_dir'],\n",
    "    in_list=in_file,\n",
    "    expected_list=expected,\n",
    "    bbox_format='x0y0x1y1',\n",
    "    scale=parameters['rescale'],\n",
    "    test=False,\n",
    "    )\n",
    "dataset = NewspapersDataset(\n",
    "    df=data,\n",
    "    images_path=img_paths,\n",
    "    scale=parameters['rescale'],\n",
    "    transforms=data_transform,\n",
    "    test=False,\n",
    "    )\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=parameters['batch_size'],\n",
    "    shuffle=parameters['shuffle'],\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=parameters['num_workers'],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on cpu\n",
    "device = 'cpu'\n",
    "model.to(device)\n",
    "torch.set_num_threads(1)\n",
    "cpu_device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 12/14 [19:06<03:03, 91.60s/it]"
     ]
    }
   ],
   "source": [
    "# predict on the test set\n",
    "with torch.no_grad():\n",
    "    f_out, f_tar = [], []\n",
    "    for images, targets in tqdm(dataloader):\n",
    "        images = list(img.to(cpu_device) for img in images)\n",
    "        targets = [{k: v.to(cpu_device) for k, v in t.items()} for t in targets]\n",
    "        f_tar.append(targets)\n",
    "        outputs = model(images)\n",
    "        outputs = [{k: v.to(cpu_device) for k, v in t.items()} for t in outputs]\n",
    "        f_out.append(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:00<00:00, 94.86it/s]\n"
     ]
    }
   ],
   "source": [
    "# prepare results\n",
    "pred_list, gt_list = [], []\n",
    "for i in tqdm(range(len(f_out))):\n",
    "    for ii in range(len(f_out[i])):\n",
    "        for iii in range(len(f_out[i][ii]['boxes'])):\n",
    "            # prediction\n",
    "            temp_list_pred = list(f_out[i][ii]['boxes'].detach().numpy()[iii])\n",
    "            temp_list_pred.append(f_out[i][ii]['labels'].detach().numpy()[iii])\n",
    "            temp_list_pred.append(f_out[i][ii]['scores'].detach().numpy()[iii])\n",
    "            pred_list.append(temp_list_pred)\n",
    "            # ground truth\n",
    "            temp_list_gt = list(f_tar[i][ii]['boxes'].detach().numpy()[iii])\n",
    "            temp_list_gt.append(f_tar[i][ii]['labels'].detach().numpy()[iii])\n",
    "            temp_list_gt.append([0, 0])\n",
    "            pred_list.append(temp_list_gt)\n",
    "\n",
    "final_pred_arr, final_gt_arr = np.array(pred_list), np.array(gt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_fn = MetricBuilder.build_evaluation_metric(\"map_2d\", async_mode=True, num_classes=7)\n",
    "\n",
    "for i in range(len(pred_list)):\n",
    "    metric_fn.add(final_pred_arr, final_gt_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"mAP: {metric_fn.value(iou_thresholds=np.arange(0.5, 1.0, 0.05), recall_thresholds=np.arange(0., 1.01, 0.01), mpolicy='soft')['mAP']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.09000000e+02, 2.78000000e+02, 1.23800000e+03, 8.79000000e+02,\n",
       "        6.00000000e+00, 9.99558628e-01],\n",
       "       [2.61100000e+03, 4.34000000e+02, 3.98000000e+03, 8.84000000e+02,\n",
       "        6.00000000e+00, 9.99542117e-01],\n",
       "       [1.23000000e+03, 2.81000000e+02, 1.92000000e+03, 1.01700000e+03,\n",
       "        6.00000000e+00, 9.99483943e-01],\n",
       "       ...,\n",
       "       [2.88200000e+03, 2.54300000e+03, 3.52200000e+03, 2.67400000e+03,\n",
       "        6.00000000e+00, 9.46213678e-02],\n",
       "       [9.08000000e+02, 4.45000000e+02, 2.23600000e+03, 2.41800000e+03,\n",
       "        5.00000000e+00, 7.02385679e-02],\n",
       "       [2.21700000e+03, 3.72000000e+02, 2.88500000e+03, 8.49000000e+02,\n",
       "        7.00000000e+00, 6.86615780e-02]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # prepare results\n",
    "# final_list = []\n",
    "# for i in tqdm(range(len(f_out))):\n",
    "#     for ii in range(len(f_out[i])):\n",
    "#         img_width, img_height = get_image_size.get_image_size(\n",
    "#                 parameters['image_dir'] + str(int(f_tar[i][ii]['image_name'].detach().numpy())) + '.jpg'\n",
    "#             )\n",
    "#         scaler_width = np.float(img_width)/np.float(f_tar[i][ii]['new_image_size'].detach().numpy()[0][0])\n",
    "#         scaler_height = np.float(img_height)/np.float(f_tar[i][ii]['new_image_size'].detach().numpy()[0][1])\n",
    "#         for iii in range(len(f_out[i][ii]['boxes'])):\n",
    "#             pred_boxes = f_out[i][ii]['boxes'].detach().numpy()[iii]\n",
    "#             x0 = int(round(pred_boxes[0]*scaler_width,0))\n",
    "#             y0 = int(round(pred_boxes[1]*scaler_height,0))\n",
    "#             x1 = int(round(pred_boxes[2]*scaler_width,0))\n",
    "#             y1 = int(round(pred_boxes[3]*scaler_height,0))\n",
    "#             temp_list = [x0, y0, x1, y1]\n",
    "#             temp_list.append(f_out[i][ii]['labels'].detach().numpy()[iii])\n",
    "#             temp_list.append(f_out[i][ii]['scores'].detach().numpy()[iii])\n",
    "#             final_list.append(temp_list)\n",
    "\n",
    "# final_arr = np.array(final_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('my_anaconda_dont')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "194abc17d4ddcff4b4cd4683b097beefe0e85feee2c9e783f126714953738c22"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
