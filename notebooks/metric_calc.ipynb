{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as T\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from mean_average_precision import MetricBuilder\n",
    "\n",
    "sys.path.append('../src/')\n",
    "from newspapersdataset import (\n",
    "    NewspapersDataset, \n",
    "    prepare_data_for_dataloader\n",
    ")\n",
    "from functions import (\n",
    "    from_tsv_to_list,\n",
    "    collate_fn\n",
    ")\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "from image_size import get_image_size  # source: https://github.com/scardine/image_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('../saved_models/model.pth', map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'channel': 1, \n",
    "    'rescale': [1000, 1000],\n",
    "    'batch_size': 16,\n",
    "    'shuffle': False, \n",
    "    'num_workers': 2,\n",
    "    'main_dir': '/Users/alexdrozdz/Desktop/Studia/00. Seminarium magisterskie/Master_degree/',\n",
    "    'image_dir': '/Users/alexdrozdz/Desktop/Studia/00. Seminarium magisterskie/scraped_photos_final/',\n",
    "    'annotations_dir': '/Users/alexdrozdz/Desktop/Studia/00. Seminarium magisterskie/news-navigator/',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = T.Compose([\n",
    "    T.Grayscale(num_output_channels=parameters['channel']),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.5,), (0.5,)),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data \n",
    "expected = from_tsv_to_list(parameters['annotations_dir']+'test-A/expected.tsv')\n",
    "in_file = from_tsv_to_list(parameters['annotations_dir']+'test-A/in.tsv')\n",
    "img_paths = [parameters['image_dir']+path for path in in_file]\n",
    "\n",
    "data = prepare_data_for_dataloader(\n",
    "    img_dir=parameters['image_dir'],\n",
    "    in_list=in_file,\n",
    "    expected_list=expected,\n",
    "    bbox_format='x0y0x1y1',\n",
    "    scale=parameters['rescale'],\n",
    "    test=False,\n",
    "    )\n",
    "dataset = NewspapersDataset(\n",
    "    df=data,\n",
    "    images_path=img_paths,\n",
    "    scale=parameters['rescale'],\n",
    "    transforms=data_transform,\n",
    "    test=False,\n",
    "    )\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=parameters['batch_size'],\n",
    "    shuffle=parameters['shuffle'],\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=parameters['num_workers'],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on cpu\n",
    "device = 'cpu'\n",
    "model.to(device)\n",
    "torch.set_num_threads(1)\n",
    "cpu_device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [20:48<00:00, 89.17s/it]\n"
     ]
    }
   ],
   "source": [
    "# predict on the test set\n",
    "with torch.no_grad():\n",
    "    f_out, f_tar = [], []\n",
    "    for images, targets in tqdm(dataloader):\n",
    "        images = list(img.to(cpu_device) for img in images)\n",
    "        targets = [{k: v.to(cpu_device) for k, v in t.items()} for t in targets]\n",
    "        f_tar.append(targets)\n",
    "        outputs = model(images)\n",
    "        outputs = [{k: v.to(cpu_device) for k, v in t.items()} for t in outputs]\n",
    "        f_out.append(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_out_flat = [x for xs in f_out for x in xs]\n",
    "f_tar_flat = [x for xs in f_tar for x in xs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare results\n",
    "pred_list, gt_list = [], []\n",
    "for i in range(len(f_out_flat)):\n",
    "    # prediction\n",
    "    temp_pred = []\n",
    "    for ii_pred in range(len(f_out_flat[i]['boxes'].detach().numpy())):\n",
    "        obj_pred = [int(el) for el in f_out_flat[i]['boxes'].detach().numpy()[ii_pred]]\n",
    "        obj_pred.append(f_out_flat[i]['labels'].detach().numpy()[ii_pred]-1)\n",
    "        obj_pred.append(f_out_flat[i]['scores'].detach().numpy()[ii_pred])\n",
    "        temp_pred.append(obj_pred)\n",
    "    pred_list.append(np.array(temp_pred))\n",
    "    # ground truth\n",
    "    temp_gt = []\n",
    "    for ii_gt in range(len(f_tar_flat[i]['boxes'].detach().numpy())):\n",
    "        obj_gt = [int(el) for el in f_tar_flat[i]['boxes'].detach().numpy()[ii_gt]]\n",
    "        obj_gt.append(f_tar_flat[i]['labels'].detach().numpy()[ii_gt]-1)\n",
    "        obj_gt = obj_gt + [0, 0]\n",
    "        temp_gt.append(np.array(obj_gt))\n",
    "    gt_list.append(np.array(temp_gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_fn = MetricBuilder.build_evaluation_metric(\"map_2d\", async_mode=True, num_classes=7)\n",
    "\n",
    "for i in range(len(pred_list)):\n",
    "    metric_fn.add(pred_list[i], gt_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = metric_fn.value(iou_thresholds=np.arange(0.5, 1.0, 0.05), recall_thresholds=np.arange(0., 1.01, 0.01), mpolicy='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final results\n",
    "ap_dict = {\n",
    "    'photograph': metric[0.5][0]['ap'],\n",
    "    'illustration': metric[0.5][1]['ap'],\n",
    "    'map': metric[0.5][2]['ap'],\n",
    "    'cartoon': metric[0.5][3]['ap'],\n",
    "    'editorial_cartoon': metric[0.5][4]['ap'],\n",
    "    'headline': metric[0.5][5]['ap'],\n",
    "    'advertisement': metric[0.5][6]['ap'],\n",
    "    'mAP': metric['mAP']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'photograph': 0.76625425,\n",
       " 'illustration': 0.31763086,\n",
       " 'map': 0.65815836,\n",
       " 'cartoon': 0.67715204,\n",
       " 'editorial_cartoon': 0.3822639,\n",
       " 'headline': 0.9000255,\n",
       " 'advertisement': 0.81451476,\n",
       " 'mAP': 0.5231611}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ap_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('my_anaconda_dont')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "194abc17d4ddcff4b4cd4683b097beefe0e85feee2c9e783f126714953738c22"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
