{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as T\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from mean_average_precision import MetricBuilder\n",
    "from typing import Dict\n",
    "import torchvision\n",
    "\n",
    "sys.path.append('../src/')\n",
    "from newspapersdataset import (\n",
    "    NewspapersDataset, \n",
    "    prepare_data_for_dataloader\n",
    ")\n",
    "from functions import (\n",
    "    from_tsv_to_list,\n",
    "    collate_fn\n",
    ")\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "from image_size import get_image_size  # source: https://github.com/scardine/image_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('../saved_models/model.pth', map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'channel': 1, \n",
    "    'rescale': [1000, 1000],\n",
    "    'batch_size': 16,\n",
    "    'shuffle': False, \n",
    "    'num_workers': 2,\n",
    "    'main_dir': '/Users/alexdrozdz/Desktop/Studia/00. Seminarium magisterskie/Master_degree/',\n",
    "    'image_dir': '/Users/alexdrozdz/Desktop/Studia/00. Seminarium magisterskie/scraped_photos_final/',\n",
    "    'annotations_dir': '/Users/alexdrozdz/Desktop/Studia/00. Seminarium magisterskie/news-navigator/',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = T.Compose([\n",
    "    T.Grayscale(num_output_channels=parameters['channel']),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.5,), (0.5,)),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data \n",
    "expected = from_tsv_to_list(parameters['annotations_dir']+'test-A/expected.tsv')\n",
    "in_file = from_tsv_to_list(parameters['annotations_dir']+'test-A/in.tsv')\n",
    "img_paths = [parameters['image_dir']+path for path in in_file]\n",
    "\n",
    "data = prepare_data_for_dataloader(\n",
    "    img_dir=parameters['image_dir'],\n",
    "    in_list=in_file,\n",
    "    expected_list=expected,\n",
    "    bbox_format='x0y0x1y1',\n",
    "    scale=parameters['rescale'],\n",
    "    test=False,\n",
    "    )\n",
    "dataset = NewspapersDataset(\n",
    "    df=data,\n",
    "    images_path=img_paths,\n",
    "    scale=parameters['rescale'],\n",
    "    transforms=data_transform,\n",
    "    test=False,\n",
    "    )\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=parameters['batch_size'],\n",
    "    shuffle=parameters['shuffle'],\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=parameters['num_workers'],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on cpu\n",
    "device = 'cpu'\n",
    "model.to(device)\n",
    "torch.set_num_threads(1)\n",
    "cpu_device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [20:48<00:00, 89.17s/it]\n"
     ]
    }
   ],
   "source": [
    "# predict on the test set\n",
    "with torch.no_grad():\n",
    "    f_out, f_tar = [], []\n",
    "    for images, targets in tqdm(dataloader):\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [\n",
    "            {k: v.to(device) for k, v in t.items()} for t in targets\n",
    "        ]\n",
    "\n",
    "        images = list(img.to(cpu_device) for img in images)\n",
    "        targets = [{k: v.to(cpu_device) for k, v in t.items()} for t in targets]\n",
    "        f_tar.append(targets)\n",
    "        outputs = model(images)\n",
    "        outputs = [{k: v.to(cpu_device) for k, v in t.items()} for t in outputs]\n",
    "        f_out.append(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('my_anaconda_dont')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "194abc17d4ddcff4b4cd4683b097beefe0e85feee2c9e783f126714953738c22"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
