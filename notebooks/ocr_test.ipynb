{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pytesseract\n",
    "from tqdm.notebook import tqdm\n",
    "import cv2\n",
    "import re\n",
    "import spacy\n",
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "import keybert\n",
    "from lib.save_load_data import from_tsv_to_list, dump_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = '/Users/alexdrozdz/Desktop/Studia/00. Seminarium magisterskie/Master_degree'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_list = from_tsv_to_list(path=f'{main_dir}/data/test-A/in.tsv')\n",
    "out_list = from_tsv_to_list(path=f'{main_dir}/data/test-A/out.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_level = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Preparing data for OCR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_data_for_ocr(in_list: List, out_list: List, confidence_level: float) -> List:\n",
    "    innout = []\n",
    "    for i in range(len(out_list)):\n",
    "        temp_out_list = out_list[i].split(' ')\n",
    "        for annotation in temp_out_list:\n",
    "            temp_annotation = annotation.split(':')\n",
    "            if float(temp_annotation[2]) >= confidence_level:\n",
    "                bbox_list = temp_annotation[1].split(',')\n",
    "            else:\n",
    "                continue            \n",
    "            innout.append([in_list[i], temp_annotation[0], int(bbox_list[0]), int(bbox_list[1]), int(bbox_list[2]), int(bbox_list[3])])\n",
    "\n",
    "    return innout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "innout = combine_data_for_ocr(in_list, out_list, confidence_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# innout = []\n",
    "# for i in range(len(out_list)):\n",
    "#     temp_out_list = out_list[i].split(' ')\n",
    "#     innout_record = []\n",
    "#     for annotation in temp_out_list:\n",
    "#         temp_annotation = annotation.split(':')\n",
    "#         if float(temp_annotation[2]) >= confidence_level:\n",
    "#             bbox_list = temp_annotation[1].split(',')\n",
    "#         else:\n",
    "#             continue            \n",
    "#         innout.append([in_list[i], temp_annotation[0], int(bbox_list[0]), int(bbox_list[1]), int(bbox_list[2]), int(bbox_list[3])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr_init() -> str:\n",
    "    return os.popen(\"brew list tesseract | grep 'bin'\").read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    pytesseract.pytesseract.tesseract_cmd = ocr_init()\n",
    "except:\n",
    "    logging.error('Tesseract OCR not found, check if you installed it correctly')\n",
    "    raise ModuleNotFoundError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs_content_dir = \"visual_content\"\n",
    "if not os.path.exists(f\"{main_dir}/vs_content_dir\"):\n",
    "    logging.info(f\"Directory '{vs_content_dir}' doesn't exist, creating one\")\n",
    "    os.makedirs(f\"{main_dir}/vs_content_dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(image: np.ndarray, x0: int, x1: int, y0: int, y1: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Crop image using bboxes\n",
    "    \"\"\"\n",
    "    return image[y0:y1, x0:x1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_transform(image: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Image transformation pipline\n",
    "    \"\"\"\n",
    "    # greyscale image\n",
    "    grey_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # dilate the image to get background (text removal)\n",
    "    dilated_img = cv2.dilate(grey_img, np.ones((7,7), np.uint8))\n",
    "    # use median blur on dilated image to get better background image containing all the shadows and discoloration\n",
    "    bg_img = cv2.medianBlur(dilated_img, 21)\n",
    "    # combine new backgorund with old image\n",
    "    diff_img = 255 - cv2.absdiff(image, bg_img)\n",
    "    # normalize the image to get full dynamic range\n",
    "    norm_img = cv2.normalize(diff_img, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8UC1)\n",
    "\n",
    "    return norm_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr_predict(image: np.ndarray) -> str:\n",
    "    \"\"\"\n",
    "    Read text from image \n",
    "    \"\"\"\n",
    "    return pytesseract.image_to_string(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr_text_clean(text: str, spacy_language_core: spacy.language.Language) -> Tuple:\n",
    "    # regex to clean and prepare text for search\n",
    "    re_clean = re.compile(\"[^a-zA-Z1-9\\s,.!?$%-']\")\n",
    "    re_search = re.compile('[^a-zA-Z1-9\\s-]')\n",
    "    # line-breaks fix\n",
    "    fixed_text = re.sub('\\n', ' ', re.sub('-\\n',  '', text))\n",
    "    # clean text\n",
    "    clean_txt = re_clean.sub('', fixed_text)\n",
    "    clean_txt = re.sub(' +', ' ', clean_txt)\n",
    "    # prepare text for search engine\n",
    "    search_txt = re_search.sub('', fixed_text)\n",
    "    search_txt = re.sub('-',  ' ', search_txt)\n",
    "    search_txt = \" \".join([token.lemma_.lower() for token in spacy_language_core(search_txt) if not token.is_stop and not token.is_punct])\n",
    "    search_txt = re.sub(' +', ' ', search_txt)\n",
    "\n",
    "    return clean_txt, search_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keywords(ocr_text: str, keybert_model: keybert.KeyBERT, top_n: int=10) -> List:\n",
    "    keywords = keybert_model.extract_keywords(ocr_text, keyphrase_ngram_range=(1, 1), stop_words='english', highlight=False, top_n=top_n)\n",
    "    return list(dict(keywords).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final dict to save\n",
    "final_dict = {}\n",
    "\n",
    "# spacy language core\n",
    "logging.info(\"Loading Spacy language core\")\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except:\n",
    "    logging.error('Spacy language core not found, check if you installed it correctly')\n",
    "    raise ModuleNotFoundError()\n",
    "\n",
    "# keybert model to extract keywords\n",
    "logging.info(\"Loading KeyBERT pretrained model\")\n",
    "kw_model = keybert.KeyBERT(model='all-mpnet-base-v2')\n",
    "\n",
    "# regex to clean and prepare text for search\n",
    "re_clean = re.compile(\"[^a-zA-Z1-9\\s,.!?$%-']\")\n",
    "re_search = re.compile('[^a-zA-Z1-9\\s-]')\n",
    "\n",
    "logging.info(\"Cropping visual contents, transforming, using OCR, cleaning results and saving\")\n",
    "for i, elem in tqdm(enumerate(innout)):\n",
    "    # read image\n",
    "    img = cv2.imread(f'{main_dir}/scraped_photos/{elem[0]}')\n",
    "\n",
    "    # crop visual content\n",
    "    # x0, y0, x1, y1 = elem[2], elem[3], elem[4], elem[5]\n",
    "    # cropped_img = img[y0:y1, x0:x1]\n",
    "    cropped_img = crop_image(img, elem[2], elem[4], elem[3], elem[5])\n",
    "\n",
    "    # # greyscale image\n",
    "    # cropped_img = cv2.cvtColor(cropped_img, cv2.COLOR_BGR2GRAY)\n",
    "    # # dilate the image to get background (text removal)\n",
    "    # dilated_img = cv2.dilate(cropped_img, np.ones((7,7), np.uint8))\n",
    "    # # use median blur on dilated image to get better background image containing all the shadows and discoloration\n",
    "    # bg_img = cv2.medianBlur(dilated_img, 21)\n",
    "    # # combine new backgorund with old image\n",
    "    # diff_img = 255 - cv2.absdiff(cropped_img, bg_img)\n",
    "    # # normalize the image to get full dynamic range\n",
    "    # norm_img = cv2.normalize(diff_img, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8UC1)\n",
    "    transformed_cropped_img = image_transform(cropped_img)\n",
    "\n",
    "    # ocr \n",
    "    # cropped_img_str = pytesseract.image_to_string(cropped_img)\n",
    "    cropped_img_str = ocr_predict(transformed_cropped_img)\n",
    "    \n",
    "    # # clean text\n",
    "    # fixed_cropped_img_str = re.sub('\\n', ' ', re.sub('-\\n',  '', cropped_img_str))\n",
    "    # # clean text to show\n",
    "    # clean_txt = re_clean.sub('', fixed_cropped_img_str)\n",
    "    # clean_txt = re.sub(' +', ' ', clean_txt)\n",
    "    # # preprocessed text to use in search\n",
    "    # search_txt = re_search.sub('', fixed_cropped_img_str)\n",
    "    # search_txt = re.sub('-',  ' ', search_txt)\n",
    "    # search_txt = \" \".join([token.lemma_.lower() for token in nlp(search_txt) if not token.is_stop and not token.is_punct])\n",
    "    # search_txt = re.sub(' +', ' ', search_txt)\n",
    "    clean_txt, search_txt = ocr_text_clean(cropped_img_str, spacy_language_core=nlp)\n",
    "\n",
    "    # keywords\n",
    "    # keywords = kw_model.extract_keywords(search_txt, keyphrase_ngram_range=(1, 1), stop_words='english', highlight=False, top_n=10)\n",
    "    # keywords_list = list(dict(keywords).keys())\n",
    "    keywords_list = get_keywords(search_txt, top_n=10, keybert_model=kw_model)\n",
    "\n",
    "    # save results\n",
    "    in_dict = {'origin_file': elem[0], 'predicted_label': elem[1], 'ocr_raw_text': cropped_img_str, 'cleaned_text': clean_txt.strip(), 'search_text': search_txt.strip(), 'keywords': keywords_list}\n",
    "    cv2.imwrite(f\"{main_dir}/visual_content/vs_{i}.png\", cropped_img)\n",
    "\n",
    "    final_dict[f\"vs_{i}.png\"] = in_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_dir = \"ocr_results\"\n",
    "if not os.path.exists(f\"{main_dir}/ocr_results\"):\n",
    "    logging.info(f\"Directory '{ocr_dir}' doesn't exist, creating one\")\n",
    "    os.makedirs(f\"{main_dir}/ocr_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_json(path=f'{ocr_dir}/vs_ocr_data.json', dict_to_save=final_dict)\n",
    "logging.info(f\"OCR output json saved in '{ocr_dir}' directory\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('magister')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2861d36cf403dae9ad4f2035439a5d607dc0edbd7f8931c1fd938c2eea51ce17"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
